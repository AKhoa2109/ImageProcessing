import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from typing import List, Tuple
import os
import sys
parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(parent_dir)
import style
style.set_sidebar_background()
st.markdown("""
    <style>
        .stApp {
            background-image: url("https://slidebazaar.com/wp-content/uploads/2024/08/Free-Professional-Background-PPT-Templates.jpg");
            /* cover‚ÄØ‚Üí‚ÄØl√†m ƒë·∫ßy, nh∆∞ng c√≥ th·ªÉ crop; contain‚ÄØ‚Üí‚ÄØv·ª´a ƒë·ªß, gi·ªØ nguy√™n t·ªâ l·ªá */
            background-size: contain;     
            background-position: center;
            background-repeat: no-repeat;
            background-attachment: fixed;
            min-height: 100vh;           /* ƒë·∫£m b·∫£o lu√¥n cao t·ªëi thi·ªÉu 100% chi·ªÅu cao c·ª≠a s·ªï */
            width: 100%;                 /* ƒë·∫£m b·∫£o lu√¥n r·ªông 100% */
        }
        .stApp > header,
        .stApp > footer {
            background-color: transparent;
        }
        .stApp > .main > .block-container {
            background-color: rgba(255, 255, 255, 0.9);
            padding: 2rem;
            border-radius: 10px;
            margin: 1rem;
        }
    </style>
""", unsafe_allow_html=True)

# C·∫•u h√¨nh MediaPipe
mp_face_mesh = mp.solutions.face_mesh

# ƒê·ªãnh nghƒ©a k·∫øt n·ªëi ƒë·ªÉ v·∫Ω
LEFT_EYE_CONNECTIONS = mp_face_mesh.FACEMESH_LEFT_EYE
RIGHT_EYE_CONNECTIONS = mp_face_mesh.FACEMESH_RIGHT_EYE

# ƒê·ªãnh nghƒ©a ch·ªâ s·ªë landmark ƒë·ªÉ t√≠nh EAR
LEFT_EYE_LANDMARKS = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_LANDMARKS = [362, 385, 387, 263, 373, 380]

# H·∫±ng s·ªë
EAR_THRESHOLD = 0.21  # Ng∆∞·ª°ng t·ª∑ l·ªá m·∫Øt

def calculate_ear(eye_idxs: List[int], landmarks: List[Tuple[float, float]]) -> float:
    """
    T√≠nh to√°n t·ª∑ l·ªá khung m·∫Øt (Eye Aspect Ratio - EAR)
    
    Args:
        eye_idxs: Danh s√°ch ch·ªâ s·ªë c·ªßa c√°c ƒëi·ªÉm landmark m·∫Øt
        landmarks: Danh s√°ch t·ªça ƒë·ªô c√°c ƒëi·ªÉm landmark
        
    Returns:
        float: Gi√° tr·ªã EAR
    """
    # Chuy·ªÉn ƒë·ªïi c√°c ƒëi·ªÉm landmark th√†nh m·∫£ng numpy
    p0, p1, p2, p3, p4, p5 = [np.array(landmarks[i]) for i in eye_idxs]
    
    # T√≠nh kho·∫£ng c√°ch d·ªçc 1 (t·ª´ p1 ƒë·∫øn p5)
    vertical1 = np.linalg.norm(p1 - p5)
    
    # T√≠nh kho·∫£ng c√°ch d·ªçc 2 (t·ª´ p2 ƒë·∫øn p4)
    vertical2 = np.linalg.norm(p2 - p4)
    
    # T√≠nh kho·∫£ng c√°ch ngang (t·ª´ p0 ƒë·∫øn p3)
    horizontal = np.linalg.norm(p0 - p3)
    
    # T√≠nh EAR: (t·ªïng kho·∫£ng c√°ch d·ªçc) / (2 * kho·∫£ng c√°ch ngang)
    return (vertical1 + vertical2) / (2.0 * horizontal)

def process_frame(image):
    """
    X·ª≠ l√Ω frame ·∫£nh ƒë·ªÉ ph√°t hi·ªán ch·ªõp m·∫Øt v√† v·∫Ω landmarks
    
    Args:
        image: Frame ·∫£nh ƒë·∫ßu v√†o
        
    Returns:
        image: Frame ·∫£nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† v·∫Ω landmarks
    """
    h, w = image.shape[:2]  # L·∫•y k√≠ch th∆∞·ªõc ·∫£nh
    
    # Kh·ªüi t·∫°o FaceMesh v·ªõi c√°c tham s·ªë
    with mp_face_mesh.FaceMesh(
        max_num_faces=1,  # Ch·ªâ ph√°t hi·ªán 1 khu√¥n m·∫∑t
        refine_landmarks=True,  # L√†m m·ªãn landmarks
        min_detection_confidence=0.5,  # ƒê·ªô tin c·∫≠y t·ªëi thi·ªÉu cho ph√°t hi·ªán
        min_tracking_confidence=0.5  # ƒê·ªô tin c·∫≠y t·ªëi thi·ªÉu cho tracking
    ) as face_mesh:
        # Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ BGR sang RGB
        rgb_frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # X·ª≠ l√Ω frame v·ªõi FaceMesh
        results = face_mesh.process(rgb_frame)
        
        if results.multi_face_landmarks:
            # L·∫•y landmarks c·ªßa khu√¥n m·∫∑t ƒë·∫ßu ti√™n
            lm = results.multi_face_landmarks[0]
            
            # Chuy·ªÉn ƒë·ªïi landmarks th√†nh t·ªça ƒë·ªô
            landmarks = [(p.x, p.y) for p in lm.landmark]
            
            # T√≠nh EAR cho m·∫Øt tr√°i v√† ph·∫£i
            left_ear = calculate_ear(LEFT_EYE_LANDMARKS, landmarks)
            right_ear = calculate_ear(RIGHT_EYE_LANDMARKS, landmarks)
            
            # T√≠nh EAR trung b√¨nh
            avg_ear = (left_ear + right_ear) / 2.0

            # X√°c ƒë·ªãnh tr·∫°ng th√°i m·∫Øt
            eye_closed = avg_ear < EAR_THRESHOLD

            # Ph√°t hi·ªán chuy·ªÉn ƒë·ªïi tr·∫°ng th√°i m·∫Øt
            if eye_closed and not st.session_state.previous_closed:
                st.session_state.eye_closed = True
            elif not eye_closed and st.session_state.previous_closed:
                st.session_state.blink_counter += 1
                st.session_state.eye_closed = False

            # C·∫≠p nh·∫≠t tr·∫°ng th√°i tr∆∞·ªõc ƒë√≥
            st.session_state.previous_closed = eye_closed

            # V·∫Ω c√°c k·∫øt n·ªëi m·∫Øt
            for connection in [LEFT_EYE_CONNECTIONS, RIGHT_EYE_CONNECTIONS]:
                for start, end in connection:
                    # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô t∆∞∆°ng ƒë·ªëi th√†nh t·ªça ƒë·ªô pixel
                    x1 = int(lm.landmark[start].x * w)
                    y1 = int(lm.landmark[start].y * h)
                    x2 = int(lm.landmark[end].x * w)
                    y2 = int(lm.landmark[end].y * h)
                    # V·∫Ω ƒë∆∞·ªùng k·∫øt n·ªëi
                    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 1)
                    
        return image

def main():
    """
    H√†m ch√≠nh c·ªßa ·ª©ng d·ª•ng
    """
    st.title("Ph√°t hi·ªán ch·ªõp m·∫Øt th·ªùi gian th·ª±c üëÅÔ∏è")

    # Kh·ªüi t·∫°o c√°c bi·∫øn session state
    if 'blink_counter' not in st.session_state:
        st.session_state.blink_counter = 0  # ƒê·∫øm s·ªë l·∫ßn ch·ªõp m·∫Øt
    if 'previous_closed' not in st.session_state:
        st.session_state.previous_closed = False  # Tr·∫°ng th√°i m·∫Øt tr∆∞·ªõc ƒë√≥
    if 'eye_closed' not in st.session_state:
        st.session_state.eye_closed = False  # Tr·∫°ng th√°i m·∫Øt hi·ªán t·∫°i

    # T·∫°o c√°c n√∫t ƒëi·ªÅu khi·ªÉn
    start = st.button("B·∫Øt ƒë·∫ßu ph√°t hi·ªán")
    stop = st.button("D·ª´ng")

    if start:
        # M·ªü camera
        cap = cv2.VideoCapture(0)
        
        # T·∫°o c√°c placeholder ƒë·ªÉ hi·ªÉn th·ªã
        img_placeholder = st.empty()  # Hi·ªÉn th·ªã ·∫£nh
        count_placeholder = st.empty()  # Hi·ªÉn th·ªã s·ªë l·∫ßn ch·ªõp m·∫Øt
        status_placeholder = st.empty()  # Hi·ªÉn th·ªã tr·∫°ng th√°i m·∫Øt

        # X·ª≠ l√Ω t·ª´ng frame
        while cap.isOpened():
            if stop:
                break
                
            # ƒê·ªçc frame t·ª´ camera
            ret, frame = cap.read()
            if not ret:
                break
                
            # L·∫≠t ·∫£nh ƒë·ªÉ hi·ªÉn th·ªã nh∆∞ g∆∞∆°ng
            frame = cv2.flip(frame, 1)
            
            # X·ª≠ l√Ω frame
            processed = process_frame(frame)

            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            img_placeholder.image(processed, channels="BGR", use_container_width=True)
            count_placeholder.markdown(f"**S·ªë l·∫ßn ch·ªõp m·∫Øt:** {st.session_state.blink_counter}")
            status = "ƒê√≥ng m·∫Øt" if st.session_state.eye_closed else "M·ªü m·∫Øt"
            status_placeholder.markdown(f"**Tr·∫°ng th√°i:** {status}")

        # Gi·∫£i ph√≥ng camera
        cap.release()

if __name__ == "__main__":
    main()